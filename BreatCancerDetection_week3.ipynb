{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PARAMETERS\n",
    "\n",
    "1. diagnosis - the diagnosis of breast tissues (M = malignant, B = benign)\n",
    "2. radius_mean - mean of distances from center to points on the perimeter or the mean radii of cells\n",
    "3. texture_mean - standard deviation of gray-scale values\n",
    "4. perimeter_mean - mean size of the core tumor\n",
    "5. area_mean - mean area of the core tumor\n",
    "6. smoothness_mean - mean of local variation in radius lengths\n",
    "7. compactness_mean - mean of perimeter^2 / area - 1.0\n",
    "8. concavity_mean - mean of severity of concave portions of the contour\n",
    "9. concave points_mean - mean for number of concave portions of the contour\n",
    "10. symmetry_mean - mean of the symmetry of division\n",
    "11. fractal_dimension_mean - mean for \"coastline approximation\" - 1\n",
    "12. radius_se - standard error for the mean of distances from center to points on the perimeter\n",
    "13. texture_se - standard error for standard deviation of gray-scale values\n",
    "14. perimeter_se - standard error for standard deviation of perimeter values\n",
    "15. area_se - standard error for standard deviation of area values\n",
    "16. smoothness_se - standard error for local variation in radius lengths\n",
    "17. compactness_se - standard error for perimeter^2 / area - 1.0\n",
    "18. concavity_se - standard error for severity of concave portions of the contour\n",
    "19. concave points_se - standard error for number of concave portions of the contour\n",
    "20. symmetry_se -standar error for symmetry in divison \n",
    "21. fractal_dimension_se - standard error for \"coastline approximation\" - 1\n",
    "22. radius_worst - \"worst\" or largest mean value for mean of distances from center to points on the perimeter\n",
    "23. texture_worst - \"worst\" or largest mean value for standard deviation of gray-scale values\n",
    "24. perimeter_worst - \"worst\" or largest mean value for standard deviation of perimeter values\n",
    "25. area_worst - \"worst\" or largest mean value for standard deviation of area values\n",
    "26. smoothness_worst - \"worst\" or largest mean value for local variation in radius lengths\n",
    "27. compactness_worst - \"worst\" or largest mean value for perimeter^2 / area - 1.0\n",
    "28. concavity_worst - \"worst\" or largest mean value for severity of concave portions of the contour\n",
    "29. concave points_worst - \"worst\" or largest mean value for number of concave portions of the contour\n",
    "30. symmetry_worst - \"worst\" or largest mean value for division\n",
    "31. fractal_dimension_worst - \"worst\" or largest mean value for \"coastline approximation\" - 1\n",
    "\n",
    "DISTRIBUTIONS:\n",
    "\n",
    "GAUSSIAN DISTRIBUTION :\n",
    "Gaussian Distribution is also known as Normal Distribution. It is a probability distribution that is symmetric abput the mean. When graphed, the Gaussian Distribution takes the shape of a bell curve. This shows that the observations near the mean have a higher chance of occuring than the observations away from the mean. For a normal distribution, 68% of the observations are within +/- one standard deviation of the mean, 95% are within +/- two standard deviations, and 99.7% are within +/- three standard deviations. The normal distribution is the most commonly used distribution.\n",
    "\n",
    "BINOMIAL DISTRIBUTION :\n",
    "The Binomial Distribution is a probability distribution that predicts the likelihood that a value will take one of the two values in a set of assumptions. The underlying assumptions of the binomial distribution are that there is only one outcome for each trial, that each trial has the same probability of success, and that each trial is mutually exclusive, or independent of each other. The binomial distribution only counts two states, typically represented as 1 (for a success) or 0 (for a failure) given a number of trials in the data.\n",
    "\n",
    "DIFFERENCE BETWEEN GAUSSIAN AND BINOMIAL DISTRIBUTION :\n",
    "The main difference between normal distribution and binomial distribution is binomial distribution is discrete. This means that in binomial distribution there are no data points between any two data points. This is very different from a normal distribution which has continuous data points. There are a finite amount of events in a binomial distribution, but an infinite number in a normal distribution.But, if the sample size for binomial distribution is large enough, its shape will be quite similar to that of normal distribution.\n",
    "\n",
    "ALGORITHMS:\n",
    "\n",
    "LOGISTIC REGRESSION :\n",
    "Logistic Regression is used to perform binary classification. The \"logit\" function is used in Logistic Regression. The logit function is called the link function because it “links” the probability to the linear function of the predictor variables. The name \"Logistic\" Regression is because of the use of the logit function. It predicts the probability of an observation belonging to any of the two target classes.\n",
    "\n",
    "DECISION TREE CLASSIFIER :\n",
    "Decision Tree identifies the most significant variable and its value that gives the best homogenous sets of population. It splits the observations in such a way that the homogenity between the split sets is maximised. The aim is to increase the homogenity which can also be interpreted as reducing the impurity. If there is a high non linearity and complex relationship between dependent and independent variables, a tree model will outperform a regression method. The commonly used splitting measures for a decision tree are Gini index, Chi-square, Information gain (Entropy) and Reduction in variance.\n",
    "\n",
    "RANDOM FOREST CLASSIFIER :\n",
    "The random forest is a classification algorithm consisting of many decisions trees. It operates by constructing multiple decision trees at training time and outputting the class that is the mode of the classes of the individual trees. It is a type of \"ensemble\" learning method. The idea behind Random Forest is that a large number of tress working together will outperform any individual tree. The reason for this is that the trees protect each other from their individual errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
